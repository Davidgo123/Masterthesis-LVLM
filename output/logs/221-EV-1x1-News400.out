Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/nfs/home/ernstd/miniconda3/envs/transformer/lib/python3.12/site-packages/transformers/models/llava/configuration_llava.py:103: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:56<01:53, 56.72s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:03<00:27, 27.58s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:11<00:00, 18.31s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:11<00:00, 23.73s/it]
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Python version is above 3.10, patching the collections module.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.24s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:00,  1.03it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]
        persons & 656 & \textbf{0.53} & 0.3 \\
        locations & 483 & \textbf{0.69} & 0.5 \\
        events & 46 & 0.28 & \textbf{0.74} \\
