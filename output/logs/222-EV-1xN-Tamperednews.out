Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/nfs/home/ernstd/miniconda3/envs/transformer/lib/python3.12/site-packages/transformers/models/llava/configuration_llava.py:103: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect
  warnings.warn(
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.54s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.49s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.39s/it]
/nfs/home/ernstd/miniconda3/envs/transformer/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. 
  warnings.warn(str(msg))
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Python version is above 3.10, patching the collections module.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.14it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.26it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]
/nfs/home/ernstd/miniconda3/envs/transformer/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:870: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. 
  warnings.warn(str(msg))
Traceback (most recent call last):
  File "/nfs/home/ernstd/masterthesis_scripts/./experiments/02_with_comparative_images/22_multi_input_models/222_entity_verification_1xN/scripts/tamperednews/analyze_answers.py", line 113, in <module>
    computeAnswer(args)
  File "/nfs/home/ernstd/masterthesis_scripts/./experiments/02_with_comparative_images/22_multi_input_models/222_entity_verification_1xN/scripts/tamperednews/analyze_answers.py", line 70, in computeAnswer
    probabilities['no'].append(float(question['no']))
                                     ~~~~~~~~^^^^^^
KeyError: 'no'
Traceback (most recent call last):
  File "/nfs/home/ernstd/masterthesis_scripts/./experiments/02_with_comparative_images/22_multi_input_models/222_entity_verification_1xN/scripts/tamperednews/printResultTable.py", line 62, in <module>
    printResults(args)
  File "/nfs/home/ernstd/masterthesis_scripts/./experiments/02_with_comparative_images/22_multi_input_models/222_entity_verification_1xN/scripts/tamperednews/printResultTable.py", line 40, in printResults
    with open(f"./output/statistics/{modelname}.csv", 'r') as file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: './output/statistics/222_EV_1xN-tamperednews-mantis.csv'
