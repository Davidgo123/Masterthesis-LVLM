Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:07,  2.36s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.89s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.63s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.40s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.07it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.03it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.07it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.06it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:01<00:07,  1.59s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:03<00:06,  1.52s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:04<00:04,  1.43s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:05<00:02,  1.40s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:07<00:01,  1.36s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.26s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.94s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.79s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.34s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.86s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.93s/it]
Some weights of the model checkpoint at /nfs/home/ernstd/models/llava-v1.6-mistral-7b-hf/ were not used when initializing LlavaForConditionalGeneration: ['image_newline']
- This IS expected if you are initializing LlavaForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlavaForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Traceback (most recent call last):
  File "/nfs/home/ernstd/masterthesis_scripts/0_document_verification/scripts/mmg/analyze_answers.py", line 100, in <module>
    computeAnswer(args)
  File "/nfs/home/ernstd/masterthesis_scripts/0_document_verification/scripts/mmg/analyze_answers.py", line 65, in computeAnswer
    if testlabel not in model['statistic'][entityType]:
                        ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
KeyError: 'continent'
        \textbf{0.96} & 0.52 & 0.94 & 0.91 & 0.89 \\
        0.9 & 0.49 & \textbf{0.92} & 0.88 & 0.83 \\
        \textbf{0.91} & 0.47 & 0.89 & 0.84 & 0.83 \\
        \textbf{0.92} & 0.43 & \textbf{0.92} & 0.88 & 0.81 \\

